11.07.10 Предотвращение перегрузки сервера - управление потоком входящих данных.

Для предотвращения перегрузки используем простой подход: если системный вызов
send/write/writev вернул EAGAIN, то перестаём ставить новые сообщения в очередь
отправки соединения до тех пор, пока не будут отправлены все данные, которые уже
находятся в очереди.

Отправку данных выполняет Sender. Есть две активных связки Sender'ов:
    ImmediateConnectionSender -> ConnectionSenderImpl
    DeferredConnectionSender  -> ConnectionSenderImpl

В общем случае о получении EAGAIN узнаём в произвольном месте (необязательно
именно в потоке, опбрабатывающем события для данного соединения). После
получения EAGAIN нужно перестать принимать новые данные из соединения (а нужно
ли?). Рассмотрим этот вопрос подробнее.

Q: Что нужно сделать для предотвращения перегрузки сервера, если выясняется, что
   мы имеем дело с медленным клиентом?

A: Во-первых, нужно начать отбрасывать сообщения, предназначенные клиенту.
   О том, какие сообщения можно отбрасывать, известно только на уровне
   бизнес-логики. Поэтому именно на уровне бизнес-логики нужно управлять работой
   при перегрузке.

   Во-вторых, нужно ограничить приём новых сообщений от медленного клиента. Это
   даст клиенту понять, что сервер испытвает затруднения с его обслуживанием
   (через механизм flow control протокола TCP). С другой стороны, сообщения типа
   ping reply нужно принимать от клиента постоянно. А вот отвечать на ping
   request не стоит, потому что немедленные ответы на ping request невозможно
   отбросить, что даст клиенту возможность для искуственной перегрузки очереди
   отправки сообщений на сервере.

   Можно было бы ввести отдельный порог для прекращения приёма данных от
   клиента. Например, предельное количество сообщений (или объём данных) в
   очереди отправки. Это означает, что есть два отдельных режима управления
   перегрузкой. Первый - после получения EAGAIN при записи в сокет - ограничение
   на отправку данных в сокет бизнес-логикой. Второй - заполнение очереди
   отправки клиенту - ограничение на приём данных от клиента. Это - хорошее
   разделение. Принимаю его. Можно ввести и третий уровень - двухкратное
   превышение длины очереди отправки. При этом можно выполнить нештатный разрыв
   соединения.

Как бы я ни выполнил механизм flow control, он всегда будет неполным. Можно
очень долго выдумывать всевозможные правила, помогающие справиться с перегрузкой
на сервере. Поэтому принятое решение неизбежно будет компромиссным и не будет
поддаваться чистой абстракции. Нужно выбрать для описанных выше правил наиболее
простое и логичное представление.

Основной узел, принимающий отдельные сообщения на отправку - это Sender.
На уровне Sender'а нужно принимать решения о прохождении барьеров, привязанных
к длине очереди отправки. Можно ввести набор фиксированных состояний очереди:
    ConnectionReady - нормальное состояние, нет перегрузки;
    ConnectionOverloaded - получен EAGAIN при записи в сокет;
    QueueSoftLimit - достигнут первый порог заполнения очереди;
    QueueHardLimit - достигнут второй порог заполнения очереди.

Эти состояния связаны и представляют собой набор возможных состояний соединения
с точки зрения отправки данных. Как построить управление перегрузкой на основе
этих состояний?

Нужно уведомлять о переходах между состояниями код бизнес-логики. Для этого
подойдёт Frontend Sender'а. Заводим в нём callback "sendStateChanged", который
будет вызываться каждый раз при смене состояния соединения. Первоначальное
соединение, подразумевающееся до первого вызова callback'а - ConnectionReady.

Лимиты soft и hard устанавливаются индивидуально для каждого Sender'а
бизнес-логикой. Лимит 0 означает отсутствие лимита.

В каких единицах устанавливать лимиты на длину очереди?

Одна из особенностей видеопотока состоит в том, что можно "прореживать" очередь
отправки сообщений при обнаружении перегрузки соединения. Наиболее простой
вариант реализации - при отправке сообщений помечать их как "droppable" (так и
сделаю: это полностью покроет все текущие потребности).

